I"uÄ<p>A Markov decision process (MDP) can be optimized using various reinforcement learning techniques. Sometimes the best way to optimize the decision process is using the Monte Carlo sampling technique, in particular, when:</p>
<ul>
  <li>The model of the environment is very big, and it is difficult to store it.</li>
  <li>The size of the MDP is big since the computation needed to update the value of each state depends only on the length of the episode and not on the size of the MDP.</li>
  <li>One needs to evaluate each state independently.</li>
</ul>

<p style="text-align:center;"><img src="/asset/images/reinforcement/mc_downhill.png" alt="mc_downhill" width="600" /></p>

<h3 id="toy-model">Toy model</h3>
<p>To illustrate how one can use the Monte Carlo technique we use a simple toy model consisting of a track. The agent starts on one side and moves towards the opposite one, choosing the best path to avoid uphill segments. He receives 0 reward when going downhill, a negative reward when turning and a negative reward when riding uphill, proportional to the steepness.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SIZE_X</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">SIZE_T</span> <span class="o">=</span> <span class="mi">150</span>

<span class="k">def</span> <span class="nf">do_action</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">action</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span>
    <span class="k">if</span> <span class="n">action</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">min</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">SIZE_X</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span>
    <span class="k">if</span> <span class="n">action</span><span class="o">==</span><span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span>
    
<span class="k">def</span> <span class="nf">calculate_reward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
    <span class="n">u_init</span> <span class="o">=</span> <span class="n">field</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span>
    <span class="n">xp</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">do_action</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
    <span class="n">u_fin</span> <span class="o">=</span> <span class="n">field</span><span class="p">[</span><span class="n">xp</span><span class="p">,</span> <span class="n">tp</span><span class="p">]</span>
    <span class="n">movement_reward</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">action</span><span class="o">==</span><span class="mi">0</span> <span class="k">else</span> <span class="o">-</span><span class="mf">0.05</span>
    <span class="k">return</span> <span class="nb">min</span><span class="p">(</span><span class="n">u_fin</span><span class="o">-</span><span class="n">u_init</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<p>The track is randomly generated as follows:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">ndimage</span>

<span class="k">def</span> <span class="nf">bin_image</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">binsize_x</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">binsize_y</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">agg_func</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">):</span>
    <span class="n">sy</span><span class="p">,</span> <span class="n">sx</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">binsize_y</span><span class="p">:</span>
        <span class="n">binsize_y</span> <span class="o">=</span> <span class="n">binsize_x</span>
        
    <span class="n">y_bins</span><span class="p">,</span> <span class="n">x_bins</span> <span class="o">=</span> <span class="n">sy</span> <span class="o">//</span> <span class="n">binsize_y</span><span class="p">,</span> <span class="n">sx</span> <span class="o">//</span> <span class="n">binsize_x</span>
    <span class="n">crop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ogrid</span><span class="p">[(</span><span class="n">sy</span> <span class="o">%</span> <span class="n">binsize_y</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="p">:</span> <span class="n">sy</span><span class="o">-</span><span class="p">((</span><span class="n">sy</span> <span class="o">%</span> <span class="n">binsize_y</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="o">+</span><span class="p">(</span><span class="n">sy</span><span class="o">%</span><span class="n">binsize_y</span><span class="p">)</span><span class="o">%</span><span class="mi">2</span><span class="p">),</span>
                   <span class="p">(</span><span class="n">sx</span> <span class="o">%</span> <span class="n">binsize_x</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="p">:</span> <span class="n">sx</span><span class="o">-</span><span class="p">((</span><span class="n">sx</span> <span class="o">%</span> <span class="n">binsize_x</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="o">+</span><span class="p">(</span><span class="n">sx</span><span class="o">%</span><span class="n">binsize_x</span><span class="p">)</span><span class="o">%</span><span class="mi">2</span><span class="p">)]</span>
    <span class="n">cropped</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">crop</span><span class="p">)]</span>
    <span class="n">x_agg</span> <span class="o">=</span> <span class="n">agg_func</span><span class="p">(</span><span class="n">cropped</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">cropped</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_bins</span><span class="p">,</span> <span class="n">binsize_x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">agg_func</span><span class="p">(</span><span class="n">x_agg</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y_bins</span><span class="p">,</span> <span class="n">binsize_y</span><span class="p">,</span> <span class="n">x_agg</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">field</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">300</span><span class="p">,</span> <span class="mi">1500</span><span class="p">])</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">field</span> <span class="o">=</span> <span class="n">ndimage</span><span class="o">.</span><span class="n">gaussian_filter</span><span class="p">(</span><span class="n">field</span><span class="p">,</span> <span class="mi">25</span><span class="p">)</span>
<span class="n">field</span> <span class="o">=</span> <span class="n">bin_image</span><span class="p">(</span><span class="n">field</span><span class="p">,</span> <span class="n">binsize_x</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">field</span> <span class="o">=</span> <span class="n">field</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">field</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">field</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="mf">0.02</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">22</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">field</span><span class="p">)</span>
</code></pre></div></div>
<p style="text-align:center;"><img src="/asset/images/reinforcement/track.png" alt="track" width="600" /></p>

<h3 id="helper-functions">Helper functions</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">initialize_policy</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">SIZE_X</span><span class="p">,</span> <span class="n">SIZE_T</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">initialize_state_values</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">SIZE_X</span><span class="p">,</span> <span class="n">SIZE_T</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">action_argmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">xp</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">do_action</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
        <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="n">xp</span><span class="p">,</span> <span class="n">tp</span><span class="p">]</span> <span class="o">+</span> <span class="n">calculate_reward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">values</span><span class="o">==</span><span class="n">np</span><span class="o">.</span><span class="nb">max</span><span class="p">(</span><span class="n">values</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    
<span class="k">def</span> <span class="nf">off_policy_action</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">loop_states</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">SIZE_T</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">SIZE_X</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span>

<span class="k">def</span> <span class="nf">plot_path</span><span class="p">(</span><span class="n">pi</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">22</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">field</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span>
    <span class="n">reward</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pi</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">)</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">pi</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">pi</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]))</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">+</span> <span class="n">calculate_reward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">do_action</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">reward</span>
</code></pre></div></div>

<h3 id="exploring-start-monte-carlo">Exploring start Monte Carlo</h3>
<p>If we perform actions using a completely greedy policy, i.e. always choosing the action that leads to the highest values state, we cannot be sure to explore the whole phase space. One possibe solution is to use <strong>exploring starts</strong>. The idea is to select the first state and the first action complitly at random. This way we can ensure taht all the phase space will be eventually explored.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">update_action_value_function_MC</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">Q_n</span><span class="p">,</span> <span class="n">pi</span><span class="p">):</span>
    <span class="n">episodes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">SIZE_X</span><span class="p">)</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">SIZE_T</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">reward</span> <span class="o">=</span> <span class="n">calculate_reward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
    <span class="n">episodes</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">SIZE_T</span><span class="o">-</span><span class="n">t</span><span class="o">-</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">do_action</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pi</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:])</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="n">calculate_reward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
        <span class="n">episodes</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">))</span>

    <span class="n">G</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">episodes</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">episode</span>
        <span class="n">G</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">*</span><span class="n">G</span> <span class="o">+</span> <span class="n">r</span>
        <span class="n">Q_n</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">Q_n</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">Q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">Q_n</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">G</span> <span class="o">-</span> <span class="n">Q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">Q</span><span class="p">,</span> <span class="n">Q_n</span>

<span class="k">def</span> <span class="nf">optimize_path_MC</span><span class="p">():</span>
    <span class="n">pi</span> <span class="o">=</span> <span class="n">initialize_policy</span><span class="p">()</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">initialize_state_values</span><span class="p">()</span>
    <span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">SIZE_X</span><span class="p">,</span> <span class="n">SIZE_T</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">Q_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">SIZE_X</span><span class="p">,</span> <span class="n">SIZE_T</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">Q</span><span class="p">,</span> <span class="n">Q_n</span> <span class="o">=</span> <span class="n">update_action_value_function_MC</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">Q_n</span><span class="p">,</span> <span class="n">pi</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">loop_states</span><span class="p">():</span>
            <span class="n">pi</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">max_actions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span><span class="o">==</span><span class="n">np</span><span class="o">.</span><span class="nb">max</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]))[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">max_actions</span><span class="p">:</span>
                <span class="n">pi</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">max_actions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">yield</span> <span class="n">pi</span>
</code></pre></div></div>

<h3 id="epsilon-greedy-mc">Epsilon greedy MC</h3>
<p>A second strategy to avoid using exploring starts consists in exploiting an epsilon-greedy strategy, which again garantees to explore the full phase space eventually. The problem with epsilon greedy policy is that it is suboptimal both for acting and learning.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">update_action_value_function_MC_eps</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">Q_n</span><span class="p">,</span> <span class="n">pi</span><span class="p">):</span>
    <span class="n">episodes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">SIZE_X</span><span class="p">)</span>
    <span class="n">t</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">reward</span> <span class="o">=</span> <span class="n">calculate_reward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
    <span class="n">episodes</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">SIZE_T</span><span class="o">-</span><span class="n">t</span><span class="o">-</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">do_action</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pi</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:])</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="n">calculate_reward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
        <span class="n">episodes</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">))</span>

    <span class="n">G</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">episodes</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">episode</span>
        <span class="n">G</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">*</span><span class="n">G</span> <span class="o">+</span> <span class="n">r</span>
        <span class="n">Q_n</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">Q_n</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">Q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">Q_n</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">G</span> <span class="o">-</span> <span class="n">Q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">Q</span><span class="p">,</span> <span class="n">Q_n</span>

<span class="k">def</span> <span class="nf">optimize_path_MC_eps</span><span class="p">():</span>
    <span class="n">pi</span> <span class="o">=</span> <span class="n">initialize_policy</span><span class="p">()</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">initialize_state_values</span><span class="p">()</span>
    <span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">SIZE_X</span><span class="p">,</span> <span class="n">SIZE_T</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">Q_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">SIZE_X</span><span class="p">,</span> <span class="n">SIZE_T</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">Q</span><span class="p">,</span> <span class="n">Q_n</span> <span class="o">=</span> <span class="n">update_action_value_function_MC_eps</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">Q_n</span><span class="p">,</span> <span class="n">pi</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">loop_states</span><span class="p">():</span>
            <span class="n">pi</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">max_actions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span><span class="o">==</span><span class="n">np</span><span class="o">.</span><span class="nb">max</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]))[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">max_actions</span><span class="p">:</span>
                <span class="n">pi</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">max_actions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">yield</span> <span class="n">pi</span>
</code></pre></div></div>

<h2 id="off-policy-learning-mc">Off policy learning MC</h2>
<p>A third possible strategy is to exploit off-policy learning, which improve and evaluate a different policy from the one used to select actions. Naturally, the behavioural policy (the one choosing the action) must cover the target policy.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">update_action_value_function_MC_offpol</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">pi</span><span class="p">):</span>
    <span class="n">episodes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">SIZE_X</span><span class="p">)</span>
    <span class="n">t</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">reward</span> <span class="o">=</span> <span class="n">calculate_reward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
    <span class="n">episodes</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">SIZE_X</span><span class="p">,</span> <span class="n">SIZE_T</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>
    

    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">SIZE_T</span><span class="o">-</span><span class="n">t</span><span class="o">-</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">do_action</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">b</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]))</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="n">calculate_reward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
        <span class="n">episodes</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">))</span>

    <span class="n">G</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">W</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">episodes</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">episode</span>
        <span class="n">G</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">*</span><span class="n">G</span> <span class="o">+</span> <span class="n">r</span>
        <span class="n">C</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">C</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">+</span> <span class="n">W</span>
        <span class="n">Q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">+</span> <span class="n">W</span><span class="o">/</span><span class="n">C</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">G</span> <span class="o">-</span> <span class="n">Q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">])</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">W</span> <span class="o">/</span><span class="n">b</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">Q</span><span class="p">,</span> <span class="n">C</span>

<span class="k">def</span> <span class="nf">optimize_path_MC_offpol</span><span class="p">():</span>
    <span class="n">pi</span> <span class="o">=</span> <span class="n">initialize_policy</span><span class="p">()</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">initialize_state_values</span><span class="p">()</span>
    <span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">SIZE_X</span><span class="p">,</span> <span class="n">SIZE_T</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">SIZE_X</span><span class="p">,</span> <span class="n">SIZE_T</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">Q</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">update_action_value_function_MC_offpol</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">pi</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">loop_states</span><span class="p">():</span>
            <span class="n">pi</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">max_actions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span><span class="o">==</span><span class="n">np</span><span class="o">.</span><span class="nb">max</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]))[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">max_actions</span><span class="p">:</span>
                <span class="n">pi</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">max_actions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">yield</span> <span class="n">pi</span>
</code></pre></div></div>
<h2 id="comparison">Comparison</h2>
<p>Here we show a comparison between of the performances relative to the three algorithm above. We run each simulation as follows in order to average 10 different runs. Each run consists in 50000 steps.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>
<span class="n">rewards_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">optimize_path_algorithm</span><span class="p">()</span> <span class="c1"># for example optimize_path_MC_offpol()
</span>    <span class="n">rewards</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_path_reward</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">s</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
    <span class="n">rewards_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span>                   
</code></pre></div></div>
<p>The comparison in show in the plot below togheter with the optimal solution obtained using an <a href="/reinforcement_learning/2019/10/06/iterative-policy-eval.html">iterative policy evaluation mathod</a>:</p>
<p style="text-align:center;"><img src="/asset/images/reinforcement/mc_comparison.png" alt="mc_comparison" width="450" /></p>
:ET